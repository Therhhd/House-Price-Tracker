{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Importing Libraries\n",
        "Let's start by importing the necessary libraries. These include TensorFlow, Keras, and the Boston housing dataset."
      ],
      "metadata": {
        "id": "zKt4T7anGPcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.datasets import boston_housing"
      ],
      "metadata": {
        "id": "QxW5pkOqGQkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Loading and Preprocessing the Boston Housing Dataset\n",
        "The Boston Housing dataset contains information collected by the U.S. Census Service concerning housing in the area of Boston, Massachusetts. The features in this dataset are used to predict the price of houses."
      ],
      "metadata": {
        "id": "FSeJ6GYAGhm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Boston Dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
      ],
      "metadata": {
        "id": "lv8c3E0bGi-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Normalizing the Data\n",
        "To ensure the data is on a similar scale, we normalize the input features. This step is essential for improving the performance and convergence speed of the LSTM model.\n"
      ],
      "metadata": {
        "id": "jGNGQiYiLM4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean and standard deviation from training data\n",
        "mean = x_train.mean(axis=0)\n",
        "std = x_train.std(axis=0)\n",
        "\n",
        "# Normalize the training and testing data\n",
        "x_train = (x_train - mean) / std\n",
        "x_test = (x_test - mean) / std\n"
      ],
      "metadata": {
        "id": "5Gsc9Ng5LVfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Reshaping Data for LSTM\n",
        "LSTM models expect data in a 3D shape, specifically [samples, time steps, features]. Since the Boston Housing dataset isn't inherently sequential, we need to reshape it to fit into the LSTM input format."
      ],
      "metadata": {
        "id": "neYUkf5CLanL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape data to fit LSTM input: [samples, time steps, features]\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n"
      ],
      "metadata": {
        "id": "4YAduvGmLcpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Building the LSTM Model\n",
        "We construct the LSTM model using Keras' Sequential API. The model consists of multiple LSTM layers with dropout regularization and a final dense layer to output the predicted house price.\n",
        "\n"
      ],
      "metadata": {
        "id": "TQHJ_HJNLhgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add LSTM layers with Dropout regularization\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Adding eight more LSTM layers with dropout\n",
        "for _ in range(13):\n",
        "    model.add(LSTM(units=50, return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "# The output layer\n",
        "model.add(Dense(units=1))\n"
      ],
      "metadata": {
        "id": "ITLm9Ex_LirE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Compiling the Model\n",
        "We compile the model with the Adam optimizer and the Mean Squared Error loss function, which is appropriate for regression tasks."
      ],
      "metadata": {
        "id": "QFLNrYJXMWFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "PFRLgGYAMXuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Training the Model\n",
        "We train the model on the training data for 10 epochs with a batch size of 32. The model will learn to predict house prices based on the input features."
      ],
      "metadata": {
        "id": "mCvaYHGEMf3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "id": "o0GnvVrXMg9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Evaluating the Model\n",
        "Finally, we evaluate the model's performance on the test data to understand how well it generalizes to unseen data."
      ],
      "metadata": {
        "id": "qYCcDb_OXa5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss = model.evaluate(x_test, y_test)\n",
        "print(f'Test Loss: {test_loss}')\n"
      ],
      "metadata": {
        "id": "xnPZnO9aXfNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ". Making Predictions (Optional)\n",
        "Once the model is trained, you can use it to make predictions on new data. Here's how you can do that:"
      ],
      "metadata": {
        "id": "FOu-qNtrXoar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Display the first five predictions\n",
        "for i in range(5):\n",
        "    print(f'Predicted: {predictions[i]}, Actual: {y_test[i]}')\n"
      ],
      "metadata": {
        "id": "cffMXFv2Xqgj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}